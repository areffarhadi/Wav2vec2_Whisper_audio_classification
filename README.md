# Wav2vec2 audio classification
Using this script, we can implement several scenarios in audio classification, such as speaker identification, language recognition, emotion recognition, sentiment analysis and more, using Wav2vec2 and Whisper models. 

For fine-tuning the Whisper model for audio classification: [Whisper_Emotion.py](https://github.com/areffarhadi/Wav2vec2_audio_classification/blob/main/Whisper_Emotion.py) <be>

For fine-tuning Wav2Vec2 for audio classification: [wav2vec_Emotion.py](https://github.com/areffarhadi/Wav2vec2_audio_classification/blob/main/wav2vec_Emotion.py)

The manifest for feeding wav data must be like [train_voice_emotion.csv](https://github.com/areffarhadi/Wav2vec2_audio_classification/blob/main/train_voice_emotion.csv) file.


